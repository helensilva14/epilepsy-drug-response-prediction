{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../') # add root folder project path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs on current machine: 40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import itertools\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from base.plot_graphs import plot_confusion_matrix, plot_normalized_confusion_matrix, plot_roc_curve, plot_ecdf\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, LeaveOneOut, GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# check number of processors on current machine\n",
    "print(\"Number of CPUs on current machine: %d\" % multiprocessing.cpu_count())\n",
    "\n",
    "# select the processor to be used (comment if processors >= 4)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get preprocessed data (241 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>  |  (241, 1309)\n",
      "<class 'pandas.core.series.Series'>  |  241\n"
     ]
    }
   ],
   "source": [
    "X = pickle.load(open( \"../../data/preprocessed/article-genetic-data-features.p\", \"rb\"))\n",
    "y = pickle.load(open( \"../../data/preprocessed/article-genetic-data-labels.p\", \"rb\"))\n",
    "\n",
    "print(type(X), \" | \", X.shape)\n",
    "print(type(y), \" | \", len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best params from parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams_dt = pickle.load(open( \"./best-params/dt-gridsearch-params.p\", \"rb\"))\n",
    "bestparams_rf = pickle.load(open( \"./best-params/rf-gridsearch-params.p\", \"rb\"))\n",
    "bestparams_svc = pickle.load(open( \"./best-params/svc-gridsearch-params.p\", \"rb\"))\n",
    "bestparams_gbm = pickle.load(open( \"./best-params/gbm-gridsearch-params.p\", \"rb\"))\n",
    "bestparams_xgb = pickle.load(open( \"./best-params/xgb-gridsearch-params.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to be used to perform model fitting using LOOCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X, y):  \n",
    "    # prepare a LOOCV object (number of folds equals the number of samples)\n",
    "    loocv = LeaveOneOut()\n",
    "    loocv.get_n_splits(X)\n",
    "    \n",
    "    # perform cross-validation and get the accuracies\n",
    "    cv_score = cross_val_score(model, X, y, cv=loocv, scoring='accuracy') \n",
    "    \n",
    "    # perform cross-validation and get the predictions and prediction probabilities\n",
    "    preds = cross_val_predict(model, X, y, cv=loocv)\n",
    "    predprobs_responsive = cross_val_predict(model, X, y, cv=loocv, method='predict_proba')[:,1]\n",
    "    predprobs_refractory = cross_val_predict(model, X, y, cv=loocv, method='predict_proba')[:,0]\n",
    "    \n",
    "    # calculate fpr and tpr values using the y_true and predictions probabilities\n",
    "    fpr, tpr, _ = metrics.roc_curve(y, predprobs_responsive)\n",
    "    \n",
    "    # calculate the auc score based on fpr and tpr values\n",
    "    auc_score = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # generate the confusion matrix for the model results and slice it into four pieces\n",
    "    cm = metrics.confusion_matrix(y, preds)\n",
    "    TP, TN, FP, FN = cm[1, 1], cm[0, 0], cm[0, 1], cm[1, 0]\n",
    "    \n",
    "    # print model information\n",
    "    print(model)\n",
    "\n",
    "    # print classification report\n",
    "    print(\"\\nAccuracy (CV Score) : Mean - %.7g | Std - %.7g\" % (np.mean(cv_score), np.std(cv_score)))\n",
    "    print(\"\\nAUC Score : %f\" % auc_score)\n",
    "    \n",
    "    # calculate sensitivity score\n",
    "    # specificity: When the actual value is negative, how often is the prediction correct?\n",
    "    # how \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "    specificity = TN / float(TN + FP)\n",
    "    print(\"\\nSpecificity Score : %f\" % specificity)\n",
    "    \n",
    "    # calculate sensitivity score\n",
    "    # sensitivity: When the actual value is positive, how often is the prediction correct?\n",
    "    # how \"sensitive\" is the classifier to detecting positive instances? Also known as \"True Positive Rate\" or \"Recall\"\n",
    "    sensitivity = TP / float(TP + FN)\n",
    "    print(\"\\Sensitivity Score : %f\" % sensitivity)\n",
    "    \n",
    "    # print a complete classification metrics report\n",
    "    print(\"\\n\" + metrics.classification_report(y, preds)) \n",
    "    \n",
    "    # get current model name\n",
    "    model_name = str(model).split('(')[0]\n",
    "    \n",
    "    test = model.predict(X)\n",
    "    print(test)\n",
    "    \n",
    "    # generate plots\n",
    "    plot_confusion_matrix(cm, model_name, 'loocv-bestparams-genetic')\n",
    "    plot_normalized_confusion_matrix(cm, model_name, 'loocv-bestparams-genetic') \n",
    "    plot_roc_curve(fpr, tpr, auc_score, model_name, 'loocv-bestparams-genetic')\n",
    "    \n",
    "    return predprobs_responsive, predprobs_refractory, preds, fpr, tpr, auc_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DecisionTreeClassifier model using the found best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 16,\n",
       " 'random_state': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestparams_dt['random_state'] = 10\n",
    "bestparams_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=4, min_samples_split=16,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
      "            splitter='best')\n",
      "\n",
      "Accuracy (CV Score) : Mean - 0.7842324 | Std - 0.4113538\n",
      "\n",
      "AUC Score : 0.793054\n",
      "\n",
      "Specificity Score : 0.901235\n",
      "\\Sensitivity Score : 0.544304\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       162\n",
      "           1       0.73      0.54      0.62        79\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       241\n",
      "   macro avg       0.77      0.72      0.74       241\n",
      "weighted avg       0.78      0.78      0.77       241\n",
      "\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9a9669fd9648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# perform model fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdt_predprobs_responsive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_predprobs_refractory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# export values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5b0182f4f814>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'('\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/codes/helen/env_helen/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \"\"\"\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/codes/helen/env_helen/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(**bestparams_dt)\n",
    "\n",
    "# perform model fitting\n",
    "dt_predprobs_responsive, dt_predprobs_refractory, dt_preds, fpr_dt, tpr_dt, auc_dt = fit_model(dt, X, y)\n",
    "\n",
    "# export values\n",
    "pickle.dump(dt_predprobs_responsive, open(\"../predictions/dt-loocv-bestparams-genetic-predprobs.p\", \"wb\"))\n",
    "pickle.dump(dt_preds, open(\"../predictions/dt-loocv-bestparams-genetic-preds.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RandomForestClassifier model using the found best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams_rf['random_state'] = 10\n",
    "bestparams_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**bestparams_rf)\n",
    "\n",
    "# perform model fitting\n",
    "rf_predprobs_responsive, rf_predprobs_refractory, rf_preds, fpr_rf, tpr_rf, auc_rf = fit_model(rf, X, y)\n",
    "\n",
    "# export values\n",
    "pickle.dump(rf_predprobs_responsive, open(\"../predictions/rf-loocv-bestparams-genetic-predprobs.p\", \"wb\"))\n",
    "pickle.dump(rf_preds, open(\"../predictions/rf-loocv-bestparams-genetic-preds.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SVM model using the found best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams_svc['probability'] = True\n",
    "bestparams_svc['random_state'] = 10\n",
    "\n",
    "bestparams_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(**bestparams_svc)\n",
    "\n",
    "# perform model fitting\n",
    "svc_predprobs_responsive, svc_predprobs_refractory, svc_preds, fpr_svc, tpr_svc, auc_svc = fit_model(svc, X, y)\n",
    "\n",
    "# export values\n",
    "pickle.dump(svc_predprobs_responsive, open(\"../predictions/svc-loocv-bestparams-genetic-predprobs.p\", \"wb\"))\n",
    "pickle.dump(svc_preds, open(\"../predictions/svc-loocv-bestparams-genetic-preds.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a GBM using the found best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams_gbm['random_state'] = 10\n",
    "\n",
    "bestparams_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(**bestparams_gbm)\n",
    "\n",
    "# perform model fitting\n",
    "gbm_predprobs_responsive, gbm_predprobs_refractory, gbm_preds, fpr_gbm, tpr_gbm, auc_gbm = fit_model(gbm, X, y)\n",
    "\n",
    "# export values\n",
    "pickle.dump(gbm_predprobs_responsive, open(\"../predictions/gbm-loocv-bestparams-genetic-predprobs.p\", \"wb\"))\n",
    "pickle.dump(gbm_preds, open(\"../predictions/gbm-loocv-bestparams-genetic-preds.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a XGB baseline model using default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams_xgb['random_state'] = 10\n",
    "\n",
    "bestparams_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**bestparams_xgb)\n",
    "\n",
    "# ignore deprecation warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "# perform model fitting\n",
    "xgb_predprobs_responsive, xgb_predprobs_refractory, xgb_preds, fpr_xgb, tpr_xgb, auc_xgb = fit_model(xgb, X, y)\n",
    "\n",
    "# export values\n",
    "pickle.dump(xgb_predprobs_responsive, open(\"../predictions/xgb-loocv-bestparams-genetic-predprobs.p\", \"wb\"))\n",
    "pickle.dump(xgb_preds, open(\"../predictions/xgb-loocv-bestparams-genetic-preds.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare all generated ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction probabilities from individual classifiers\n",
    "dt_predprobs = pickle.load( open( \"../predictions/dt-loocv-bestparams-genetic-predprobs.p\", \"rb\" ) )\n",
    "rf_predprobs = pickle.load( open( \"../predictions/rf-loocv-bestparams-genetic-predprobs.p\", \"rb\" ) )\n",
    "svc_predprobs = pickle.load( open( \"../predictions/svc-loocv-bestparams-genetic-predprobs.p\", \"rb\" ) )\n",
    "gbm_predprobs = pickle.load( open( \"../predictions/gbm-loocv-bestparams-genetic-predprobs.p\", \"rb\" ) )\n",
    "xgb_predprobs = pickle.load( open( \"../predictions/xgb-loocv-bestparams-genetic-predprobs.p\", \"rb\" ) )\n",
    "\n",
    "# calculate fpr, tpr and auc score for all models using the y_true and its predictions probabilities\n",
    "fpr_dt, tpr_dt, _ = metrics.roc_curve(y, dt_predprobs)\n",
    "auc_dt = metrics.auc(fpr_dt, tpr_dt)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = metrics.roc_curve(y, rf_predprobs)\n",
    "auc_rf = metrics.auc(fpr_rf, tpr_rf)\n",
    "\n",
    "fpr_svc, tpr_svc, _ = metrics.roc_curve(y, svc_predprobs)\n",
    "auc_svc = metrics.auc(fpr_svc, tpr_svc)\n",
    "\n",
    "fpr_gbm, tpr_gbm, _ = metrics.roc_curve(y, gbm_predprobs)\n",
    "auc_gbm = metrics.auc(fpr_gbm, tpr_gbm)\n",
    "\n",
    "fpr_xgb, tpr_xgb, _ = metrics.roc_curve(y, xgb_predprobs)\n",
    "auc_xgb = metrics.auc(fpr_xgb, tpr_xgb)\n",
    "\n",
    "# plot all roc curves into the same image\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')  , \n",
    "plt.plot(fpr_dt, tpr_dt, color='aqua', label='DT (AUC = %f)' % auc_dt)\n",
    "plt.plot(fpr_rf, tpr_rf, color='cornflowerblue', label='RF (AUC = %f)' % auc_rf)\n",
    "plt.plot(fpr_svc, tpr_svc, color='darkorange', label='SVM (AUC = %f)' % auc_svc)\n",
    "plt.plot(fpr_gbm, tpr_gbm, color='deeppink', label='GB (AUC = %f)' % auc_gbm)\n",
    "plt.plot(fpr_xgb, tpr_xgb, color='navy', label='XG (AUC = %f)' % auc_xgb)\n",
    "plt.xlabel('False positive rate') # False positive rate\n",
    "plt.ylabel('True positive rate') # True positive rate\n",
    "# plt.title('Comparison of ROC curves of ') # Drug Response Prediction - ROC Curve\n",
    "plt.legend(loc='lower right')\n",
    "# save plot as image \n",
    "plt.savefig('../figures/roc-curves/loocv-bestparams-genetic-models-comparison-roc-curves-v2.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the ECDF (empirical cumulative distribution function) of the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PS: XGBoost is the best classifier, but if its results can not be loaded, Gradient Boosting is the second best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predprobs_responsive, predprobs_refactory = gbm_predprobs_responsive, gbm_predprobs_refractory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ecdf(predprobs_responsive, predprobs_refactory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_helen",
   "language": "python",
   "name": "env_helen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
